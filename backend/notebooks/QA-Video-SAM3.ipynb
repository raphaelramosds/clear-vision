{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29682813",
   "metadata": {},
   "source": [
    "# QA Video SAM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3497fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Include clear_vision modulo on PYTHONPATH\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c029cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32mINFO 2025-11-22 20:27:50,498 49627 sam3_video_predictor.py: 299:\u001b[0m using the following GPU IDs: [0]\n",
      "\u001b[0m\u001b[32mINFO 2025-11-22 20:27:50,511 49627 sam3_video_predictor.py: 315:\u001b[0m \n",
      "\n",
      "\n",
      "\t*** START loading model on all ranks ***\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[32mINFO 2025-11-22 20:27:50,513 49627 sam3_video_predictor.py: 317:\u001b[0m loading model on rank=0 with world_size=1 -- this could take a while ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/rapha/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/assets/bpe_simple_vocab_16e6.txt.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msam3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_sam3_video_predictor\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m video_predictor = \u001b[43mbuild_sam3_video_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/sam3/model_builder.py:791\u001b[39m, in \u001b[36mbuild_sam3_video_predictor\u001b[39m\u001b[34m(gpus_to_use, *model_args, **model_kwargs)\u001b[39m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_sam3_video_predictor\u001b[39m(*model_args, gpus_to_use=\u001b[38;5;28;01mNone\u001b[39;00m, **model_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSam3VideoPredictorMultiGPU\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_to_use\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgpus_to_use\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/sam3/model/sam3_video_predictor.py:318\u001b[39m, in \u001b[36mSam3VideoPredictorMultiGPU.__init__\u001b[39m\u001b[34m(self, gpus_to_use, *model_args, **model_kwargs)\u001b[39m\n\u001b[32m    315\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m*** START loading model on all ranks ***\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    317\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloading model on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.rank_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -- this could take a while ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloading model on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.rank_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -- DONE locally\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.world_size > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rank == \u001b[32m0\u001b[39m:\n\u001b[32m    322\u001b[39m     \u001b[38;5;66;03m# start the worker processes *after* the model is loaded in the main process\u001b[39;00m\n\u001b[32m    323\u001b[39m     \u001b[38;5;66;03m# so that the main process can run torch.compile and fill the cache first\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/sam3/model/sam3_video_predictor.py:43\u001b[39m, in \u001b[36mSam3VideoPredictor.__init__\u001b[39m\u001b[34m(self, checkpoint_path, bpe_path, has_presence_token, geo_encoder_use_img_cross_attn, strict_state_dict_loading, async_loading_frames, video_loader_type, apply_temporal_disambiguation)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m.video_loader_type = video_loader_type\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msam3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_sam3_video_model\n\u001b[32m     42\u001b[39m \u001b[38;5;28mself\u001b[39m.model = (\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mbuild_sam3_video_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbpe_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbpe_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_presence_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_presence_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeo_encoder_use_img_cross_attn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeo_encoder_use_img_cross_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict_state_dict_loading\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict_state_dict_loading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapply_temporal_disambiguation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapply_temporal_disambiguation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     .cuda()\n\u001b[32m     52\u001b[39m     .eval()\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/sam3/model_builder.py:680\u001b[39m, in \u001b[36mbuild_sam3_video_model\u001b[39m\u001b[34m(checkpoint_path, load_from_HF, bpe_path, has_presence_token, geo_encoder_use_img_cross_attn, strict_state_dict_loading, apply_temporal_disambiguation, device, compile)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;66;03m# Build Detector components\u001b[39;00m\n\u001b[32m    679\u001b[39m visual_neck = _create_vision_backbone()\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m text_encoder = \u001b[43m_create_text_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbpe_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m backbone = SAM3VLBackbone(scalp=\u001b[32m1\u001b[39m, visual=visual_neck, text=text_encoder)\n\u001b[32m    682\u001b[39m transformer = _create_sam3_transformer(has_presence_token=has_presence_token)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/sam3/model_builder.py:488\u001b[39m, in \u001b[36m_create_text_encoder\u001b[39m\u001b[34m(bpe_path)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_text_encoder\u001b[39m(bpe_path: \u001b[38;5;28mstr\u001b[39m) -> VETextEncoder:\n\u001b[32m    487\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create SAM3 text encoder.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     tokenizer = \u001b[43mSimpleTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbpe_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbpe_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m VETextEncoder(\n\u001b[32m    490\u001b[39m         tokenizer=tokenizer,\n\u001b[32m    491\u001b[39m         d_model=\u001b[32m256\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    494\u001b[39m         layers=\u001b[32m24\u001b[39m,\n\u001b[32m    495\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/sam3/model/tokenizer_ve.py:138\u001b[39m, in \u001b[36mSimpleTokenizer.__init__\u001b[39m\u001b[34m(self, bpe_path, additional_special_tokens, context_length, clean)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28mself\u001b[39m.byte_encoder = bytes_to_unicode()\n\u001b[32m    137\u001b[39m \u001b[38;5;28mself\u001b[39m.byte_decoder = {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.byte_encoder.items()}\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mg_pathmgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbpe_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[32m    139\u001b[39m     bpe_bytes = io.BytesIO(fh.read())\n\u001b[32m    140\u001b[39m     merges = gzip.open(bpe_bytes).read().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m).split(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/iopath/common/file_io.py:1062\u001b[39m, in \u001b[36mPathManager.open\u001b[39m\u001b[34m(self, path, mode, buffering, **kwargs)\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;66;03m# pass enable mode to handler that will be logging\u001b[39;00m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# read, write operations separately.\u001b[39;00m\n\u001b[32m   1061\u001b[39m handler.set_logging(\u001b[38;5;28mself\u001b[39m._enable_logging)\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m bret = \u001b[43mhandler\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1064\u001b[39m kvs = \u001b[38;5;28mself\u001b[39m.__get_open_keys(path, mode, buffering)\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_tmetry_keys(handler, kvs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/iopath/common/file_io.py:645\u001b[39m, in \u001b[36mNativePathHandler._open\u001b[39m\u001b[34m(self, path, mode, buffering, encoding, errors, newline, closefd, opener, **kwargs)\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[33;03mOpen a path.\u001b[39;00m\n\u001b[32m    607\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    642\u001b[39m \u001b[33;03m    file: a file-like object.\u001b[39;00m\n\u001b[32m    643\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    644\u001b[39m \u001b[38;5;28mself\u001b[39m._check_kwargs(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    646\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_path_with_cwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopener\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopener\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/rapha/.cache/pypoetry/virtualenvs/clear-vision-backend-pHRXtyny-py3.12/lib/python3.12/site-packages/assets/bpe_simple_vocab_16e6.txt.gz'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from sam3.model_builder import build_sam3_video_predictor\n",
    "\n",
    "video_predictor = build_sam3_video_predictor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clear-vision-backend-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
